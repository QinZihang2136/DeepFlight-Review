#!/usr/bin/env python
"""
LogCortex V3 - å¤šæ—¥å¿—æµ‹è¯•
æµ‹è¯•æ‰€æœ‰æ—¥å¿—æ–‡ä»¶
"""
import os
import sys
import json

# æ¸…é™¤ä»£ç†
for proxy in ['http_proxy', 'https_proxy', 'HTTP_PROXY', 'HTTPS_PROXY', 'all_proxy', 'ALL_PROXY']:
    os.environ.pop(proxy, None)

os.environ["LOGCORTEX_API_KEY"] = "b00e23d740524abba55a3072d10bda47.Mno0AlrtfrkG18I8"

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from openai import OpenAI
from modules.analyzer import LogAnalyzer
from modules.ai_agent import (
    build_tool_specs,
    execute_tool,
    build_system_prompt,
    ContextManager,
    get_preset,
    get_quick_health_check,
)


def test_all_logs():
    """æµ‹è¯•æ‰€æœ‰æ—¥å¿—æ–‡ä»¶"""
    log_dir = "/home/qinzihang/Code/FlightLog"
    log_files = [
        "log_25_2025-10-17-17-20-28.ulg",
        "log_26_2025-10-17-17-27-28.ulg",
        "log_27_2025-10-17-17-31-20.ulg",
    ]

    print("=" * 60)
    print("LogCortex V3 - å¤šæ—¥å¿— AI åˆ†ææµ‹è¯•")
    print("=" * 60)

    # åˆå§‹åŒ– GLM å®¢æˆ·ç«¯
    client = OpenAI(
        api_key=os.environ["LOGCORTEX_API_KEY"],
        base_url="https://open.bigmodel.cn/api/paas/v4",
        timeout=60.0
    )

    for log_file in log_files:
        log_path = os.path.join(log_dir, log_file)
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•æ—¥å¿—: {log_file}")
        print("=" * 60)

        try:
            # åŠ è½½æ—¥å¿—
            analyzer = LogAnalyzer(log_path)
            print(f"âœ… åŠ è½½æˆåŠŸ - æ—¶é•¿: {analyzer.duration:.1f}s, Topics: {len(analyzer.get_available_topics())}")

            # å¿«é€Ÿå¥åº·æ£€æŸ¥
            health = get_quick_health_check(analyzer)
            status = "âœ… æ­£å¸¸" if health.get("flight_ok") else "âš ï¸ æœ‰é—®é¢˜"
            print(f"   å¥åº·çŠ¶æ€: {status}")
            print(f"   æœ€å¤§é«˜åº¦: {health.get('max_alt_m', 0):.1f}m")
            print(f"   æœ€å¤§é€Ÿåº¦: {health.get('max_speed_mps', 0):.1f}m/s")

            if health.get("warnings"):
                print(f"   è­¦å‘Š ({len(health['warnings'])}):")
                for w in health["warnings"][:2]:
                    print(f"      - {w.get('type')}: {w.get('message')}")

            # AI åˆ†æ
            print(f"\n   ğŸ¤– AI åˆ†æä¸­...")
            ctx = ContextManager(max_tokens=16000)
            ctx.add_message("system", build_system_prompt(analyzer))

            preset = get_preset("quick_health")
            ctx.add_user_message(preset.user_prompt)

            tools = build_tool_specs()
            final_response = None

            for step in range(5):
                resp = client.chat.completions.create(
                    model="glm-4-flash",
                    messages=ctx.get_messages(),
                    tools=tools,
                    tool_choice="auto",
                    temperature=0.2,
                )

                msg = resp.choices[0].message
                tool_calls = getattr(msg, "tool_calls", None)

                if not tool_calls:
                    final_response = msg.content
                    break

                tool_calls_data = [
                    {
                        "id": tc.id,
                        "type": "function",
                        "function": {"name": tc.function.name, "arguments": tc.function.arguments or "{}"},
                    }
                    for tc in tool_calls
                ]
                ctx.add_assistant_message(tool_calls=tool_calls_data)

                for tc in tool_calls:
                    try:
                        args = json.loads(tc.function.arguments or "{}")
                    except:
                        args = {}
                    result = execute_tool(analyzer, tc.function.name, args)
                    ctx.add_tool_result(tc.id, tc.function.name, result)

            if final_response:
                # æ˜¾ç¤º AI å“åº”çš„å‰å‡ è¡Œ
                lines = final_response.split('\n')[:5]
                print(f"   AI å“åº”é¢„è§ˆ:")
                for line in lines:
                    if line.strip():
                        print(f"      {line[:60]}...")
                print(f"   Token ä½¿ç”¨: {ctx.total_tokens()}")

        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    print("\n" + "=" * 60)
    print("å¤šæ—¥å¿—æµ‹è¯•å®Œæˆ")
    print("=" * 60)


if __name__ == "__main__":
    test_all_logs()
