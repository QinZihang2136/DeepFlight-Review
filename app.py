import json
import os
import tempfile
import threading
import time
from queue import Queue

# ç¦ç”¨ä»£ç†ï¼ˆé¿å… GLM/DeepSeek API è¿æ¥é—®é¢˜ï¼‰
for proxy_var in ['http_proxy', 'https_proxy', 'HTTP_PROXY', 'HTTPS_PROXY', 'all_proxy', 'ALL_PROXY']:
    os.environ.pop(proxy_var, None)

import pandas as pd
import streamlit as st
from openai import OpenAI

from modules.analyzer import LogAnalyzer
from modules.ui_components import (
    render_chart,
    render_linked_subplots,
    render_comparison_chart,
)
from modules.flight_review_views import render_flight_review_dashboard_v2

# æ–°çš„ AI Agent æ¨¡å—
from modules.ai_agent import (
    build_tool_specs,
    execute_tool,
    build_system_prompt,
    ContextManager,
    DIAGNOSTIC_PRESETS,
    get_preset_names,
    get_preset,
    get_preset_prompt,
    parse_slash_command,
    get_help_text,
)


st.set_page_config(
    layout="wide",
    page_title="LogCortex V3",
    page_icon="ğŸš",
    initial_sidebar_state="collapsed",
)
st.title("ğŸš LogCortex V3: æœ¬åœ°æ—¥å¿—æŸ¥çœ‹ + AI åˆ†æ")


# =============================================================================
# AI Agent è¿è¡Œå™¨ï¼ˆå¸¦ä¸Šä¸‹æ–‡ç®¡ç†å’Œè¿›åº¦åé¦ˆï¼‰
# =============================================================================

def run_ai_agent(
    client,
    model_name: str,
    analyzer,
    user_prompt: str,
    context_manager: ContextManager,
    progress_callback=None,
    tool_callback=None,
    max_steps: int = 20,
):
    """
    è¿è¡Œ AI Agentï¼Œå¸¦ä¸Šä¸‹æ–‡ç®¡ç†å’Œè¿›åº¦åé¦ˆ

    Args:
        client: OpenAI å®¢æˆ·ç«¯
        model_name: æ¨¡å‹åç§°
        analyzer: LogAnalyzer å®ä¾‹
        user_prompt: ç”¨æˆ·è¾“å…¥
        context_manager: ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        tool_callback: å·¥å…·è°ƒç”¨å›è°ƒå‡½æ•°
        max_steps: æœ€å¤§æ­¥éª¤æ•°

    Returns:
        str: AI å“åº”å†…å®¹
    """
    tools = build_tool_specs()
    tool_call_history = []  # è®°å½•å·¥å…·è°ƒç”¨å†å²

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    context_manager.add_user_message(user_prompt)

    for step in range(max_steps):
        # è·å–å½“å‰æ¶ˆæ¯
        messages = context_manager.get_messages()

        # é€šçŸ¥è¿›åº¦
        if progress_callback:
            progress_callback(step, max_steps, "thinking")

        try:
            resp = client.chat.completions.create(
                model=model_name,
                messages=messages,
                tools=tools,
                tool_choice="auto",
                temperature=0.2,
            )
        except Exception as e:
            return f"AI è¯·æ±‚å¤±è´¥: {e}"

        msg = resp.choices[0].message
        tool_calls = getattr(msg, "tool_calls", None)

        # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›ç»“æœ
        if not tool_calls:
            content = msg.content or "æœªç”Ÿæˆæœ‰æ•ˆå†…å®¹ã€‚"
            context_manager.add_assistant_message(content)
            return content

        # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯ï¼ˆå¸¦å·¥å…·è°ƒç”¨ï¼‰
        tool_calls_data = [
            {
                "id": tc.id,
                "type": "function",
                "function": {"name": tc.function.name, "arguments": tc.function.arguments or "{}"},
            }
            for tc in tool_calls
        ]
        context_manager.add_assistant_message(tool_calls=tool_calls_data)

        # æ‰§è¡Œå·¥å…·è°ƒç”¨
        for tc in tool_calls:
            try:
                tool_args = json.loads(tc.function.arguments or "{}")
            except Exception:
                tool_args = {}

            tool_name = tc.function.name
            tool_call_history.append(tool_name)

            # é€šçŸ¥å·¥å…·è°ƒç”¨
            if tool_callback:
                tool_callback(tool_name, tool_args, "calling")

            if progress_callback:
                progress_callback(step, max_steps, f"tool:{tool_name}")

            # æ‰§è¡Œå·¥å…·
            tool_result = execute_tool(analyzer, tool_name, tool_args)

            # æ·»åŠ å·¥å…·ç»“æœï¼ˆè‡ªåŠ¨å‹ç¼©ï¼‰
            context_manager.add_tool_result(tc.id, tool_name, tool_result)

            # é€šçŸ¥å·¥å…·å®Œæˆ
            if tool_callback:
                tool_callback(tool_name, tool_args, "completed", tool_result)

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æå‰ç»ˆæ­¢ï¼ˆé‡å¤å·¥å…·è°ƒç”¨ï¼‰
        if len(tool_call_history) >= 3:
            recent_calls = tool_call_history[-3:]
            if len(set(recent_calls)) == 1:
                # è¿ç»­3æ¬¡è°ƒç”¨åŒä¸€å·¥å…·ï¼Œå¯èƒ½é™·å…¥å¾ªç¯
                context_manager.add_user_message(
                    "ä½ å·²ç»å¤šæ¬¡è°ƒç”¨åŒä¸€ä¸ªå·¥å…·ï¼Œè¯·æ ¹æ®å·²æœ‰ä¿¡æ¯ç»™å‡ºåˆ†æç»“è®ºã€‚"
                )

    # è¾¾åˆ°æ­¥æ•°ä¸Šé™ï¼Œå°è¯•è·å–éƒ¨åˆ†ç»“è®º
    stats = context_manager.get_stats()
    tools_used = list(set(tool_call_history))
    return f"""åˆ†æå·²è¾¾åˆ° {max_steps} æ­¥çš„ä¸Šé™ã€‚

**å·²è°ƒç”¨çš„å·¥å…·**: {', '.join(tools_used)}

**ä¸Šä¸‹æ–‡çŠ¶æ€**: {stats['total_tokens']} tokens ({stats['utilization']}% ä½¿ç”¨)

ğŸ’¡ **å»ºè®®**: å¯ä»¥å°è¯•ï¼š
1. ä½¿ç”¨æ›´å…·ä½“çš„é¢„è®¾ï¼ˆå¦‚ /quick å¿«é€Ÿæ£€æŸ¥ï¼‰
2. æ¸…ç©ºå¯¹è¯å†å²åé‡æ–°å¼€å§‹
3. ç¼©å°é—®é¢˜èŒƒå›´ï¼Œä¸€æ¬¡åªé—®ä¸€ä¸ªæ–¹é¢"""


def run_ai_stream(client, model_name: str, messages: list):
    """æµå¼è¾“å‡ºï¼ˆç”¨äºæ™®é€šå¯¹è¯ï¼‰"""
    full_resp = ""
    stream = client.chat.completions.create(
        model=model_name,
        messages=messages,
        stream=True,
        temperature=0.7,
    )
    for chunk in stream:
        delta = chunk.choices[0].delta.content
        if delta:
            full_resp += delta
            yield delta
    return full_resp


# =============================================================================
# æä¾›å•†é…ç½®
# =============================================================================

provider_configs = {
    "GLM": {
        "key_label": "GLM API Key",
        "base_url": "https://open.bigmodel.cn/api/paas/v4",
        "models": ["glm-5", "glm-4.7", "glm-4.5", "glm-4-air", "glm-4-flash"],
        "default_key": "",
        "default_model": "glm-5",
    },
    "DeepSeek": {
        "key_label": "DeepSeek API Key",
        "base_url": "https://api.deepseek.com",
        "models": ["deepseek-chat", "deepseek-reasoner"],
        "default_key": "",
        "default_model": "deepseek-chat",
    },
}

# =============================================================================
# UI: è¿æ¥ä¸æ—¥å¿—è®¾ç½®
# =============================================================================

with st.expander("è¿æ¥ä¸æ—¥å¿—è®¾ç½®", expanded=False):
    c1, c2, c3 = st.columns([1, 2, 2])
    with c1:
        provider = st.selectbox("AI æä¾›å•†", ["GLM", "DeepSeek"], index=0)
    provider_cfg = provider_configs[provider]
    with c2:
        env_key = os.getenv("LOGCORTEX_API_KEY", "")
        api_key = st.text_input(
            provider_cfg["key_label"],
            type="password",
            value=env_key or provider_cfg["default_key"],
        )
    with c3:
        use_custom_model = st.checkbox("è‡ªå®šä¹‰æ¨¡å‹å", value=False)
        if use_custom_model:
            default_model = provider_cfg["default_model"]
            model_name = st.text_input("æ¨¡å‹å", value=default_model)
        else:
            default_idx = (
                provider_cfg["models"].index(provider_cfg["default_model"])
                if provider_cfg["default_model"] in provider_cfg["models"]
                else 0
            )
            model_name = st.selectbox("AI æ¨¡å‹", provider_cfg["models"], index=default_idx)
    uploaded_file = st.file_uploader("ä¸Šä¼  PX4 æ—¥å¿— (.ulg)", type=["ulg", "ulog"])

client = None
if api_key:
    try:
        client = OpenAI(api_key=api_key, base_url=provider_cfg["base_url"], timeout=60.0)
        st.success(f"ğŸŸ¢ {provider} / {model_name} å·²è¿æ¥")
    except Exception as e:
        st.error(f"ğŸ”´ è¿æ¥å¤±è´¥: {e}")
else:
    st.info("å¯ç¦»çº¿æŸ¥çœ‹æ—¥å¿—ï¼›å±•å¼€ã€Œè¿æ¥ä¸æ—¥å¿—è®¾ç½®ã€åå¡«å†™ Key å¯å¯ç”¨ AIã€‚")


# =============================================================================
# Session State åˆå§‹åŒ–
# =============================================================================

if "analyzer" not in st.session_state:
    st.session_state.analyzer = None
if "messages" not in st.session_state:
    st.session_state.messages = []
if "curr_file" not in st.session_state:
    st.session_state.curr_file = None
if "context_manager" not in st.session_state:
    st.session_state.context_manager = None
if "raw_topic_selected" not in st.session_state:
    st.session_state.raw_topic_selected = None
if "favorite_signals" not in st.session_state:
    st.session_state.favorite_signals = {}
if "raw_workspace_pages" not in st.session_state:
    st.session_state.raw_workspace_pages = []
if "compare_basket" not in st.session_state:
    st.session_state.compare_basket = []
if "signal_index" not in st.session_state:
    st.session_state.signal_index = []
if "chart_tabs" not in st.session_state:
    st.session_state.chart_tabs = [{"name": "tab1", "signals": []}]
if "active_chart_tab" not in st.session_state:
    st.session_state.active_chart_tab = 0

# åå°åˆ†æç›¸å…³çŠ¶æ€
if "bg_analysis" not in st.session_state:
    st.session_state.bg_analysis = {
        "running": False,
        "status": "",
        "tool_logs": [],
        "result": None,
        "error": None,
        "user_prompt": None,
        "thread": None,
    }


# =============================================================================
# åå°åˆ†æå‡½æ•°
# =============================================================================

def run_background_analysis(client, model_name, analyzer, user_prompt, ctx_mgr, max_steps, bg):
    """åœ¨åå°çº¿ç¨‹ä¸­è¿è¡ŒAIåˆ†æ"""
    import copy

    bg["status"] = "starting"
    bg["tool_logs"] = []
    bg["result"] = None
    bg["error"] = None

    tools = build_tool_specs()
    tool_call_history = []

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡
    ctx_mgr.add_user_message(user_prompt)

    try:
        for step in range(max_steps):
            if not bg["running"]:  # æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
                bg["status"] = "cancelled"
                return

            bg["status"] = f"thinking:{step+1}/{max_steps}"
            messages = ctx_mgr.get_messages()

            resp = client.chat.completions.create(
                model=model_name,
                messages=messages,
                tools=tools,
                tool_choice="auto",
                temperature=0.2,
            )

            msg = resp.choices[0].message
            tool_calls = getattr(msg, "tool_calls", None)

            if not tool_calls:
                # å®Œæˆ
                content = msg.content or "æœªç”Ÿæˆæœ‰æ•ˆå†…å®¹ã€‚"
                ctx_mgr.add_assistant_message(content)
                bg["result"] = content
                bg["status"] = "completed"
                return

            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
            tool_calls_data = [
                {
                    "id": tc.id,
                    "type": "function",
                    "function": {"name": tc.function.name, "arguments": tc.function.arguments or "{}"},
                }
                for tc in tool_calls
            ]
            ctx_mgr.add_assistant_message(tool_calls=tool_calls_data)

            # æ‰§è¡Œå·¥å…·
            for tc in tool_calls:
                tool_name = tc.function.name
                tool_call_history.append(tool_name)
                bg["status"] = f"tool:{tool_name}"

                try:
                    tool_args = json.loads(tc.function.arguments or "{}")
                except:
                    tool_args = {}

                tool_result = execute_tool(analyzer, tool_name, tool_args)
                ctx_mgr.add_tool_result(tc.id, tool_name, tool_result)

                # è®°å½•å·¥å…·æ—¥å¿—
                if "error" not in tool_result:
                    if tool_name == "get_quick_health_check":
                        status_text = "âœ… æ­£å¸¸" if tool_result.get("flight_ok") else "âš ï¸ æœ‰é—®é¢˜"
                        bg["tool_logs"].append(f"âœ… `{tool_name}`: {status_text}")
                    elif tool_name == "get_subsystem_summary":
                        sub = tool_result.get("subsystem", "?")
                        st_text = tool_result.get("status", "?")
                        bg["tool_logs"].append(f"âœ… `{tool_name}`({sub}): {st_text}")
                    else:
                        bg["tool_logs"].append(f"âœ… `{tool_name}`: å®Œæˆ")
                else:
                    bg["tool_logs"].append(f"âŒ `{tool_name}`: å¤±è´¥")

            # å¾ªç¯æ£€æµ‹
            if len(tool_call_history) >= 3:
                recent = tool_call_history[-3:]
                if len(set(recent)) == 1:
                    ctx_mgr.add_user_message("ä½ å·²ç»å¤šæ¬¡è°ƒç”¨åŒä¸€ä¸ªå·¥å…·ï¼Œè¯·ç»™å‡ºç»“è®ºã€‚")

        # è¾¾åˆ°æ­¥æ•°ä¸Šé™
        stats = ctx_mgr.get_stats()
        tools_used = list(set(tool_call_history))
        bg["result"] = f"""åˆ†æå·²è¾¾åˆ° {max_steps} æ­¥çš„ä¸Šé™ã€‚

**å·²è°ƒç”¨çš„å·¥å…·**: {', '.join(tools_used)}

**ä¸Šä¸‹æ–‡çŠ¶æ€**: {stats['total_tokens']} tokens ({stats['utilization']}% ä½¿ç”¨)

ğŸ’¡ **å»ºè®®**: å¯ä»¥å°è¯•ï¼š
1. ä½¿ç”¨æ›´å…·ä½“çš„é¢„è®¾ï¼ˆå¦‚ /quick å¿«é€Ÿæ£€æŸ¥ï¼‰
2. æ¸…ç©ºå¯¹è¯å†å²åé‡æ–°å¼€å§‹
3. ç¼©å°é—®é¢˜èŒƒå›´"""
        bg["status"] = "completed"

    except Exception as e:
        bg["error"] = str(e)
        bg["status"] = "error"


def start_background_analysis(client, model_name, analyzer, user_prompt, ctx_mgr, max_steps):
    """å¯åŠ¨åå°åˆ†æçº¿ç¨‹"""
    bg = st.session_state.bg_analysis
    bg["running"] = True
    bg["user_prompt"] = user_prompt
    bg["saved"] = False  # é‡ç½®ä¿å­˜æ ‡å¿—
    bg["result"] = None  # æ¸…é™¤ä¸Šæ¬¡ç»“æœ
    bg["error"] = None   # æ¸…é™¤ä¸Šæ¬¡é”™è¯¯

    def run():
        run_background_analysis(client, model_name, analyzer, user_prompt, ctx_mgr, max_steps, bg)

    thread = threading.Thread(target=run, daemon=True)
    thread.start()
    bg["thread"] = thread


# =============================================================================
# è¾…åŠ©å‡½æ•°
# =============================================================================

def fuzzy_match(path, query):
    if not query.strip():
        return True
    p = path.lower()
    parts = [x for x in query.lower().strip().split() if x]
    return all(part in p for part in parts)


def build_signal_index(analyzer):
    signals = []
    for topic in analyzer.get_available_topics():
        df = analyzer.get_topic_data(topic, downsample=True)
        if df is None:
            continue
        for field in df.columns:
            if field == "timestamp":
                continue
            if df[field].dtype.kind not in "iufb":
                continue
            signals.append({
                "path": f"{topic}/{field}",
                "topic": topic,
                "field": field,
            })
    signals.sort(key=lambda x: x["path"])
    return signals


# =============================================================================
# æ—¥å¿—ä¸Šä¼ ä¸è§£æ
# =============================================================================

if uploaded_file:
    if st.session_state.analyzer is None or st.session_state.curr_file != uploaded_file.name:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".ulg") as tmp:
            tmp.write(uploaded_file.getvalue())
            path = tmp.name

        try:
            with st.spinner("æ­£åœ¨æ·±åº¦è§£ææ—¥å¿—..."):
                analyzer = LogAnalyzer(path)
                st.session_state.analyzer = analyzer
                st.session_state.curr_file = uploaded_file.name
                st.session_state.signal_index = build_signal_index(analyzer)
                st.session_state.chart_tabs = [{"name": "tab1", "signals": []}]
                st.session_state.active_chart_tab = 0

                # åˆå§‹åŒ–ä¸Šä¸‹æ–‡ç®¡ç†å™¨
                ctx_mgr = ContextManager(max_tokens=32000)
                ctx_mgr.add_message("system", build_system_prompt(analyzer))
                st.session_state.context_manager = ctx_mgr

                # ç®€å•çš„æ¶ˆæ¯å†å²ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
                st.session_state.messages = []
        except Exception as e:
            st.error(f"è§£æä¸¥é‡é”™è¯¯: {e}")


# =============================================================================
# ä¸»é¡µé¢å¯¼èˆª
# =============================================================================

if st.session_state.analyzer:
    analyzer = st.session_state.analyzer

    page = st.radio(
        "é¡µé¢å¯¼èˆª",
        ["ğŸ“Š é£è¡Œæ¦‚è§ˆ", "ğŸ’¬ AI æ™ºèƒ½åˆ†æ", "ğŸ•’ äº‹ä»¶æ—¶é—´çº¿", "âš™ï¸ å‚æ•°æµè§ˆ", "ğŸ“ˆ ç»Ÿè®¡ä¸å¼‚å¸¸", "ğŸ” åŸå§‹æ•°æ®"],
        horizontal=True,
        label_visibility="collapsed",
    )

    # =========================================================================
    # é¡µé¢: é£è¡Œæ¦‚è§ˆ
    # =========================================================================
    if page == "ğŸ“Š é£è¡Œæ¦‚è§ˆ":
        render_flight_review_dashboard_v2(analyzer)

    # =========================================================================
    # é¡µé¢: AI æ™ºèƒ½åˆ†æ
    # =========================================================================
    elif page == "ğŸ’¬ AI æ™ºèƒ½åˆ†æ":
        if not client:
            st.error("âš ï¸ AI åŠŸèƒ½ä¸å¯ç”¨ï¼šè¯·åœ¨ä¸Šæ–¹å±•å¼€ã€Œè¿æ¥ä¸æ—¥å¿—è®¾ç½®ã€å¡«å†™ API Keyã€‚")
        else:
            # è·å–æˆ–åˆå§‹åŒ–ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            if st.session_state.context_manager is None:
                ctx_mgr = ContextManager(max_tokens=32000)
                ctx_mgr.add_message("system", build_system_prompt(analyzer))
                st.session_state.context_manager = ctx_mgr
            ctx_mgr = st.session_state.context_manager

            # --- é¢„è®¾è¯Šæ–­æŒ‰é’® ---
            st.markdown("### ğŸ¯ ä¸€é”®è¯Šæ–­")
            preset_cols = st.columns(4)
            preset_names = get_preset_names()

            selected_preset = None
            for i, preset_info in enumerate(preset_names[:4]):
                with preset_cols[i]:
                    if st.button(
                        f"{preset_info['icon']} {preset_info['name']}",
                        key=f"preset_{preset_info['id']}",
                        use_container_width=True,
                    ):
                        selected_preset = preset_info['id']

            preset_cols2 = st.columns(4)
            for i, preset_info in enumerate(preset_names[4:8]):
                with preset_cols2[i]:
                    if st.button(
                        f"{preset_info['icon']} {preset_info['name']}",
                        key=f"preset_{preset_info['id']}",
                        use_container_width=True,
                    ):
                        selected_preset = preset_info['id']

            st.markdown("---")

            # --- è¿›åº¦æ˜¾ç¤ºåŒº ---
            progress_placeholder = st.empty()
            tool_log_placeholder = st.empty()

            # --- å¯¹è¯å†å² ---
            chat_container = st.container(height=500)
            for msg in st.session_state.messages:
                if msg["role"] == "user":
                    chat_container.chat_message("user").markdown(msg["content"])
                elif msg["role"] == "assistant":
                    chat_container.chat_message("assistant").markdown(msg["content"])

            # --- è¾“å…¥åŒº ---
            user_prompt = None
            chat_input = st.chat_input("è¾“å…¥é—®é¢˜ï¼Œæˆ–ä½¿ç”¨ /quick /full /gps ç­‰å‘½ä»¤")

            # å¤„ç†é¢„è®¾é€‰æ‹©
            if selected_preset:
                preset = get_preset(selected_preset)
                if preset:
                    user_prompt = f"[é¢„è®¾: {preset.name}]\n\n{preset.user_prompt}"

            # å¤„ç†èŠå¤©è¾“å…¥
            if chat_input:
                # æ£€æŸ¥æ–œæ å‘½ä»¤
                slash_preset = parse_slash_command(chat_input)
                if slash_preset == "help":
                    # æ˜¾ç¤ºå¸®åŠ©
                    st.markdown(get_help_text())
                elif slash_preset:
                    preset = get_preset(slash_preset)
                    if preset:
                        user_prompt = f"[é¢„è®¾: {preset.name}]\n\n{preset.user_prompt}"
                else:
                    user_prompt = chat_input

            # --- æ‰§è¡Œ AI åˆ†æï¼ˆåå°æ¨¡å¼ï¼‰---
            bg = st.session_state.bg_analysis

            # å¯åŠ¨æ–°çš„åˆ†æä»»åŠ¡
            if user_prompt and not bg["running"]:
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
                st.session_state.messages.append({"role": "user", "content": user_prompt})

                # è®¡ç®—æœ€å¤§æ­¥æ•°
                stats_before = ctx_mgr.get_stats()
                utilization = stats_before['utilization']
                if utilization < 30:
                    max_steps = 30
                elif utilization < 50:
                    max_steps = 20
                else:
                    max_steps = 15

                # å¯åŠ¨åå°åˆ†æ
                start_background_analysis(
                    client=client,
                    model_name=model_name,
                    analyzer=analyzer,
                    user_prompt=user_prompt,
                    ctx_mgr=ctx_mgr,
                    max_steps=max_steps,
                )
                st.rerun()

            # æ˜¾ç¤ºåå°åˆ†æçŠ¶æ€
            if bg["running"]:
                status = bg.get("status", "")
                if status.startswith("thinking:"):
                    progress_placeholder.info(f"ğŸ§  AI æ€è€ƒä¸­... ({status.split(':')[1]})")
                elif status.startswith("tool:"):
                    tool_name = status.split(":")[1]
                    progress_placeholder.info(f"ğŸ”§ è°ƒç”¨å·¥å…·: `{tool_name}`")
                else:
                    progress_placeholder.info("ğŸ”„ æ­£åœ¨åˆ†æ...")

                # æ˜¾ç¤ºå·¥å…·æ—¥å¿—
                if bg.get("tool_logs"):
                    tool_log_placeholder.markdown("\n".join(bg["tool_logs"][-8:]))

                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if bg["status"] == "completed":
                    # ä¿å­˜ç»“æœåˆ°æ¶ˆæ¯å†å²ï¼ˆä»…å½“ç»“æœæœªè¢«ä¿å­˜è¿‡ï¼‰
                    if bg.get("result") and not bg.get("saved"):
                        st.session_state.messages.append({"role": "assistant", "content": bg["result"]})
                        bg["saved"] = True  # æ ‡è®°å·²ä¿å­˜
                    bg["running"] = False
                    progress_placeholder.empty()
                    tool_log_placeholder.empty()
                    st.rerun()

                elif bg["status"] == "error":
                    error_msg = f"âŒ åˆ†æå‡ºé”™: {bg.get('error', 'æœªçŸ¥é”™è¯¯')}"
                    if not bg.get("saved"):
                        st.session_state.messages.append({"role": "assistant", "content": error_msg})
                        bg["saved"] = True
                    bg["running"] = False
                    progress_placeholder.empty()
                    tool_log_placeholder.empty()
                    st.error(error_msg)

                elif bg["status"] == "cancelled":
                    bg["running"] = False
                    progress_placeholder.warning("âš ï¸ åˆ†æå·²å–æ¶ˆ")
                    progress_placeholder.empty()
                    tool_log_placeholder.empty()

                else:
                    # ä»åœ¨è¿è¡Œï¼Œè‡ªåŠ¨åˆ·æ–°
                    time.sleep(0.5)
                    st.rerun()

            # æ˜¾ç¤ºå¯¹è¯å†å²ä¸­çš„æœ€æ–°æ¶ˆæ¯
            for msg in st.session_state.messages:
                if msg["role"] == "user":
                    chat_container.chat_message("user").markdown(msg["content"])
                elif msg["role"] == "assistant":
                    chat_container.chat_message("assistant").markdown(msg["content"])

            # --- æ˜¾ç¤ºä¸Šä¸‹æ–‡ä¿¡æ¯ ---
            with st.expander("ğŸ“Š ä¸Šä¸‹æ–‡ç®¡ç†", expanded=False):
                stats = ctx_mgr.get_stats()
                col1, col2, col3 = st.columns(3)
                col1.metric("æ¶ˆæ¯æ•°", stats["message_count"])
                col2.metric("Token æ•°", f"{stats['total_tokens']:,}")
                col3.metric("ä½¿ç”¨ç‡", f"{stats['utilization']}%")

                if st.button("æ¸…ç©ºå¯¹è¯å†å²", key="clear_chat"):
                    st.session_state.messages = []
                    ctx_mgr.clear()
                    ctx_mgr.add_message("system", build_system_prompt(analyzer))
                    st.rerun()

    # =========================================================================
    # é¡µé¢: äº‹ä»¶æ—¶é—´çº¿
    # =========================================================================
    elif page == "ğŸ•’ äº‹ä»¶æ—¶é—´çº¿":
        st.markdown("### ğŸ•’ å…³é”®äº‹ä»¶æ—¶é—´çº¿")
        max_events = st.slider("äº‹ä»¶æ•°é‡ä¸Šé™", min_value=20, max_value=300, value=120, step=20)
        timeline = analyzer.get_event_timeline(max_events=max_events)
        events = timeline.get("events", [])
        st.caption(f"å…± {timeline.get('count', 0)} æ¡äº‹ä»¶")
        if events:
            st.dataframe(events, width="stretch")
        else:
            st.info("æœªæ£€æµ‹åˆ°äº‹ä»¶")

    # =========================================================================
    # é¡µé¢: å‚æ•°æµè§ˆ
    # =========================================================================
    elif page == "âš™ï¸ å‚æ•°æµè§ˆ":
        st.markdown("### âš™ï¸ å‚æ•°æµè§ˆ")
        c1, c2 = st.columns(2)
        with c1:
            prefix = st.text_input("å‚æ•°å‰ç¼€è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰", value="")
        with c2:
            keyword = st.text_input("å‚æ•°å…³é”®å­—æœç´¢ï¼ˆå¯é€‰ï¼‰", value="")

        params = analyzer.list_parameters(
            prefix=prefix.strip() or None,
            keyword=keyword.strip() or None,
            max_results=2000,
        )
        st.caption(f"åŒ¹é…å‚æ•°æ•°é‡: {len(params)}")
        st.dataframe(params, width="stretch", height=360)

        st.markdown("#### å‚æ•°å˜æ›´è®°å½•")
        changes = analyzer.list_parameter_changes(limit=300)
        if changes:
            st.dataframe(changes, width="stretch", height=240)
        else:
            st.info("æ—¥å¿—ä¸­æ— å‚æ•°å˜æ›´è®°å½•")

    # =========================================================================
    # é¡µé¢: ç»Ÿè®¡ä¸å¼‚å¸¸
    # =========================================================================
    elif page == "ğŸ“ˆ ç»Ÿè®¡ä¸å¼‚å¸¸":
        st.markdown("### ğŸ“ˆ å•å­—æ®µç»Ÿè®¡ä¸å¼‚å¸¸æ£€æµ‹")
        topic = st.selectbox("é€‰æ‹© Topic", analyzer.get_available_topics(), key="stats_topic")
        fields = analyzer.get_topic_numeric_fields(topic)
        if not fields:
            st.warning("è¯¥ Topic æ²¡æœ‰å¯ç”¨çš„æ•°å€¼å­—æ®µ")
        else:
            field = st.selectbox("é€‰æ‹©å­—æ®µ", fields)
            threshold = st.slider("å¼‚å¸¸é˜ˆå€¼ (sigma)", min_value=1.5, max_value=5.0, value=3.0, step=0.5)

            c1, c2 = st.columns(2)
            with c1:
                stats = analyzer.compute_field_statistics(topic, field)
                st.markdown("#### æè¿°æ€§ç»Ÿè®¡")
                st.json(stats)
            with c2:
                anomalies = analyzer.detect_anomalies(topic, field, threshold_std=threshold)
                st.markdown("#### å¼‚å¸¸æ£€æµ‹")
                st.json(anomalies)

            df = analyzer.get_topic_data(topic, downsample=True)
            if df is not None and field in df.columns:
                render_chart(df, [field], f"{topic}.{field}", height=320)

    # =========================================================================
    # é¡µé¢: åŸå§‹æ•°æ®
    # =========================================================================
    elif page == "ğŸ” åŸå§‹æ•°æ®":
        st.markdown("### ğŸ”§ åŸå§‹è¯é¢˜æµè§ˆå™¨ï¼ˆPlotJuggleré£æ ¼ï¼‰")
        if not st.session_state.signal_index:
            with st.spinner("å»ºç«‹ä¿¡å·ç´¢å¼•ä¸­..."):
                st.session_state.signal_index = build_signal_index(analyzer)

        signal_index = st.session_state.signal_index
        path_map = {s["path"]: s for s in signal_index}
        all_paths = [s["path"] for s in signal_index]

        if st.session_state.active_chart_tab >= len(st.session_state.chart_tabs):
            st.session_state.active_chart_tab = max(0, len(st.session_state.chart_tabs) - 1)

        left, right = st.columns([1, 3], gap="large")

        with left:
            st.markdown("#### ä¿¡å·æœç´¢ï¼ˆå¶å­çº§ï¼‰")
            query = st.text_input("æ¨¡ç³Šæœç´¢", value="", key="leaf_query")
            matched = [p for p in all_paths if fuzzy_match(p, query)]
            st.caption(f"åŒ¹é…: {len(matched)} / {len(all_paths)}")

            list_height = st.slider("åˆ—è¡¨é«˜åº¦", min_value=220, max_value=900, value=520, step=20, key="leaf_list_height")
            show_all = st.checkbox("æ˜¾ç¤ºå…¨éƒ¨åŒ¹é…ä¿¡å·", value=True, key="leaf_show_all")
            if show_all:
                show_paths = matched
            else:
                max_show = st.slider(
                    "æœ€å¤šæ˜¾ç¤ºæ¡æ•°",
                    min_value=200,
                    max_value=max(5000, len(matched) if matched else 5000),
                    value=min(2000, len(matched) if matched else 2000),
                    step=100,
                    key="leaf_max_show",
                )
                show_paths = matched[:max_show]
            leaf_df = pd.DataFrame({
                "é€‰æ‹©": [False] * len(show_paths),
                "path": show_paths,
                "topic": [path_map[p]["topic"] for p in show_paths],
                "field": [path_map[p]["field"] for p in show_paths],
            })
            edited = st.data_editor(
                leaf_df,
                width="stretch",
                height=list_height,
                hide_index=True,
                disabled=["path", "topic", "field"],
                column_config={
                    "é€‰æ‹©": st.column_config.CheckboxColumn(help="å‹¾é€‰ååŠ å…¥å›¾è¡¨é¡µ"),
                    "path": st.column_config.TextColumn("ä¿¡å·è·¯å¾„"),
                    "topic": st.column_config.TextColumn("topic"),
                    "field": st.column_config.TextColumn("field"),
                },
                key="leaf_table_editor",
            )
            picked = edited[edited["é€‰æ‹©"]]["path"].tolist()
            st.caption(f"å·²å‹¾é€‰: {len(picked)}")

            add_c1, add_c2 = st.columns(2)
            with add_c1:
                if st.button("åŠ å…¥å½“å‰é¡µ", width="stretch", key="leaf_add_curr") and picked:
                    tab = st.session_state.chart_tabs[st.session_state.active_chart_tab]
                    for p in picked:
                        if p not in tab["signals"]:
                            tab["signals"].append(p)
                    tab_signals_key = f"tab_signals_{st.session_state.active_chart_tab}"
                    st.session_state[tab_signals_key] = tab["signals"][:]
            with add_c2:
                if st.button("æ–°å»ºé¡µå¹¶åŠ å…¥", width="stretch", key="leaf_add_new") and picked:
                    new_name = f"tab{len(st.session_state.chart_tabs)+1}"
                    st.session_state.chart_tabs.append({"name": new_name, "signals": picked[:]})
                    st.session_state.active_chart_tab = len(st.session_state.chart_tabs) - 1
                    st.rerun()

            st.markdown("#### åˆ†çº§ä¸‹æ‹‰ï¼ˆtopic -> fieldï¼‰")
            topic_filter = st.text_input("æŒ‰topicè¿‡æ»¤", value="", key="topic_filter_leaf")
            topics = analyzer.get_available_topics()
            if topic_filter.strip():
                topics = [t for t in topics if topic_filter.lower() in t.lower()]
            if not topics:
                st.warning("æ²¡æœ‰åŒ¹é…çš„ topic")
            else:
                groups = sorted({t.split("_")[0] for t in topics})
                group_selected = st.selectbox("ä¸€çº§åˆ†ç±»", groups, key="topic_group_select")
                group_topics = [t for t in topics if t.startswith(group_selected + "_") or t == group_selected]
                topic_selected = st.selectbox("Topic", group_topics, key="topic_leaf_selected")

                topic_df = analyzer.get_topic_data(topic_selected, downsample=True)
                if topic_df is not None:
                    topic_fields = [c for c in topic_df.columns if c != "timestamp" and topic_df[c].dtype.kind in "iufb"]
                    field_df = pd.DataFrame({
                        "é€‰æ‹©": [False] * len(topic_fields),
                        "field": topic_fields,
                        "signal": [f"{topic_selected}/{f}" for f in topic_fields],
                    })
                    edited_fields = st.data_editor(
                        field_df,
                        width="stretch",
                        height=260,
                        hide_index=True,
                        disabled=["field", "signal"],
                        column_config={
                            "é€‰æ‹©": st.column_config.CheckboxColumn(help="å‹¾é€‰å­—æ®µ"),
                            "field": st.column_config.TextColumn("å­—æ®µ"),
                            "signal": st.column_config.TextColumn("ä¿¡å·è·¯å¾„"),
                        },
                        key=f"topic_field_editor_{topic_selected}",
                    )
                    topic_leaf_pick = edited_fields[edited_fields["é€‰æ‹©"]]["signal"].tolist()
                    st.caption(f"è¯¥ topic å·²å‹¾é€‰å­—æ®µ: {len(topic_leaf_pick)}")

                    tf_c1, tf_c2 = st.columns(2)
                    with tf_c1:
                        if st.button("åŠ å…¥å½“å‰é¡µ", width="stretch", key=f"leaf_topic_add_curr_{topic_selected}") and topic_leaf_pick:
                            tab = st.session_state.chart_tabs[st.session_state.active_chart_tab]
                            for p in topic_leaf_pick:
                                if p not in tab["signals"]:
                                    tab["signals"].append(p)
                            tab_signals_key = f"tab_signals_{st.session_state.active_chart_tab}"
                            st.session_state[tab_signals_key] = tab["signals"][:]
                    with tf_c2:
                        if st.button("æ–°å»ºé¡µå¹¶åŠ å…¥", width="stretch", key=f"leaf_topic_add_new_{topic_selected}") and topic_leaf_pick:
                            new_name = f"tab{len(st.session_state.chart_tabs)+1}"
                            st.session_state.chart_tabs.append({"name": new_name, "signals": topic_leaf_pick[:]})
                            st.session_state.active_chart_tab = len(st.session_state.chart_tabs) - 1
                            st.rerun()

        with right:
            st.markdown("#### å›¾è¡¨é¡µé¢ï¼ˆå¯æ–°å»ºå¤šä¸ªï¼‰")
            tab_names = [f"{i+1}. {t['name']}" for i, t in enumerate(st.session_state.chart_tabs)]
            selected_tab_name = st.selectbox("å½“å‰é¡µé¢", tab_names, index=st.session_state.active_chart_tab, key="chart_tab_select")
            st.session_state.active_chart_tab = tab_names.index(selected_tab_name)

            t_c1, t_c2, t_c3, t_c4 = st.columns([2, 1, 1, 1])
            with t_c1:
                new_tab_name = st.text_input("é¡µé¢å", value=st.session_state.chart_tabs[st.session_state.active_chart_tab]["name"], key="tab_name_edit")
            with t_c2:
                if st.button("é‡å‘½å", width="stretch", key="tab_rename_btn"):
                    st.session_state.chart_tabs[st.session_state.active_chart_tab]["name"] = new_tab_name
                    st.rerun()
            with t_c3:
                if st.button("æ–°å»ºé¡µé¢", width="stretch", key="tab_new_btn"):
                    st.session_state.chart_tabs.append({"name": f"tab{len(st.session_state.chart_tabs)+1}", "signals": []})
                    st.session_state.active_chart_tab = len(st.session_state.chart_tabs) - 1
                    st.rerun()
            with t_c4:
                if st.button("åˆ é™¤é¡µé¢", width="stretch", key="tab_del_btn") and len(st.session_state.chart_tabs) > 1:
                    st.session_state.chart_tabs.pop(st.session_state.active_chart_tab)
                    st.session_state.active_chart_tab = max(0, st.session_state.active_chart_tab - 1)
                    st.rerun()

            active_tab = st.session_state.chart_tabs[st.session_state.active_chart_tab]
            active_signals = st.multiselect(
                "å½“å‰é¡µä¿¡å·",
                options=all_paths,
                default=active_tab["signals"],
                key=f"tab_signals_{st.session_state.active_chart_tab}",
            )
            active_tab["signals"] = active_signals

            cfg_c1, cfg_c2, cfg_c3 = st.columns([1, 1, 2])
            with cfg_c1:
                downsample_raw = st.checkbox("é™é‡‡æ ·", value=True, key=f"tab_downsample_{st.session_state.active_chart_tab}")
            with cfg_c2:
                show_rangeslider = st.checkbox("æ—¶é—´æ»‘æ¡", value=True, key=f"tab_rangeslider_{st.session_state.active_chart_tab}")
            with cfg_c3:
                y_mode = st.selectbox(
                    "Yè½´æ¨¡å¼",
                    ["åŸå§‹", "æ ‡å‡†åŒ–(0-1)", "æ ‡å‡†åŒ–(Z-Score)"],
                    key=f"tab_y_mode_{st.session_state.active_chart_tab}",
                )

            chart_height = st.slider(
                "å›¾è¡¨é«˜åº¦",
                min_value=420,
                max_value=1000,
                value=680,
                step=20,
                key=f"tab_chart_height_{st.session_state.active_chart_tab}",
            )

            x_range = st.slider(
                "æ—¶é—´çª—å£ (s)",
                min_value=0.0,
                max_value=float(analyzer.duration),
                value=(0.0, float(analyzer.duration)),
                step=max(float(analyzer.duration) / 800.0, 0.01),
                key=f"tab_xrange_{st.session_state.active_chart_tab}",
            )

            series_list = []
            for p in active_signals:
                info = path_map.get(p)
                if not info:
                    continue
                df = analyzer.get_topic_data(info["topic"], downsample=downsample_raw)
                if df is None or info["field"] not in df.columns:
                    continue
                dfx = df[(df["timestamp"] >= x_range[0]) & (df["timestamp"] <= x_range[1])]
                series_list.append({"name": p, "x": dfx["timestamp"], "y": dfx[info["field"]]})

            if series_list:
                render_comparison_chart(
                    series_list,
                    title=f"Chart: {active_tab['name']}",
                    height=chart_height,
                    x_range=x_range,
                    show_rangeslider=show_rangeslider,
                    normalize_mode=y_mode,
                )
            else:
                st.info("å½“å‰é¡µé¢è¿˜æ²¡æœ‰ä¿¡å·ã€‚è¯·ä»å·¦ä¾§æœç´¢å¶å­ä¿¡å·å¹¶åŠ å…¥ã€‚")

            st.markdown("#### æ•°æ®è¡¨ï¼ˆå½“å‰é¡µï¼‰")
            table_pick = st.multiselect(
                "é€‰æ‹©è¦å±•ç¤ºæ•°æ®è¡¨çš„ä¿¡å·ï¼ˆæœ€å¤š3ä¸ªï¼‰",
                options=active_signals,
                default=active_signals[:1],
                key=f"tab_tables_{st.session_state.active_chart_tab}",
            )
            table_pick = table_pick[:3]
            for p in table_pick:
                info = path_map.get(p)
                if not info:
                    continue
                df = analyzer.get_topic_data(info["topic"], downsample=False)
                if df is None or info["field"] not in df.columns:
                    continue
                show_df = df[(df["timestamp"] >= x_range[0]) & (df["timestamp"] <= x_range[1])][["timestamp", info["field"]]]
                with st.expander(f"è¡¨æ ¼: {p}", expanded=False):
                    st.dataframe(show_df.head(1000), width="stretch")
else:
    st.info("è¯·åœ¨ä¸Šæ–¹ä¸Šä¼ æ—¥å¿—æ–‡ä»¶ä»¥å¼€å§‹")
